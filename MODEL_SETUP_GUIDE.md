# Gemma 3N æ¨¡å‹è¨­ç½®æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—å°‡å¹«åŠ©æ‚¨ä¸‹è¼‰ Gemma 3N æ¨¡å‹ä¸¦è½‰æ›ç‚º TensorFlow Lite æ ¼å¼ï¼Œä»¥ä¾¿åœ¨ Android æ‡‰ç”¨ä¸­ä½¿ç”¨ã€‚

## ğŸš€ å¿«é€Ÿé–‹å§‹ï¼ˆæ¨è–¦ï¼‰

### æ–¹æ³•ä¸€ï¼šè‡ªå‹•åŒ–è…³æœ¬

1. **é‹è¡Œè¨­ç½®è…³æœ¬**ï¼š
   ```bash
   cd scripts
   chmod +x setup_model.sh
   ./setup_model.sh
   ```

2. **é¸æ“‡è¨­ç½®æ¨¡å¼**ï¼š
   - é¸æ“‡ `1` é€²è¡Œå¿«é€Ÿè¨­ç½®ï¼ˆä½¿ç”¨ä½”ä½ç¬¦æ–‡ä»¶ï¼‰
   - é¸æ“‡ `2` é€²è¡Œå®Œæ•´è¨­ç½®ï¼ˆä¸‹è¼‰çœŸå¯¦æ¨¡å‹ï¼‰

3. **ç·¨è­¯å’Œé‹è¡Œ**ï¼š
   ```bash
   cd ..
   ./gradlew assembleDebug
   ./gradlew installDebug
   ```

### æ–¹æ³•äºŒï¼šPython è…³æœ¬

```bash
cd scripts
python3 download_and_convert_model.py
```

## ğŸ“‹ è©³ç´°æ­¥é©Ÿ

### æ­¥é©Ÿ 1ï¼šæº–å‚™ç’°å¢ƒ

#### å®‰è£ Python ä¾è³´
```bash
pip install tensorflow transformers torch huggingface_hub optimum[tflite]
```

#### è¨­ç½® Hugging Face è¨ªå•
```bash
# æ–¹æ³• 1ï¼šä½¿ç”¨ CLI
huggingface-cli login

# æ–¹æ³• 2ï¼šè¨­ç½®ç’°å¢ƒè®Šé‡
export HF_TOKEN="your_huggingface_token"
```

### æ­¥é©Ÿ 2ï¼šç²å– Gemma æ¨¡å‹è¨ªå•æ¬Šé™

1. **è¨ªå• Hugging Face**ï¼š
   - å‰å¾€ [Gemma æ¨¡å‹é é¢](https://huggingface.co/google/gemma-2b)
   - é»æ“Š "Request Access"
   - å¡«å¯«ç”³è«‹è¡¨æ ¼ä¸¦ç­‰å¾…æ‰¹å‡†

2. **ç”Ÿæˆè¨ªå•ä»¤ç‰Œ**ï¼š
   - å‰å¾€ [Hugging Face Settings](https://huggingface.co/settings/tokens)
   - å‰µå»ºæ–°çš„è¨ªå•ä»¤ç‰Œ
   - é¸æ“‡ "Read" æ¬Šé™

### æ­¥é©Ÿ 3ï¼šä¸‹è¼‰å’Œè½‰æ›æ¨¡å‹

#### è‡ªå‹•è½‰æ›ï¼ˆæ¨è–¦ï¼‰
```python
# ä½¿ç”¨æä¾›çš„ Python è…³æœ¬
python3 scripts/download_and_convert_model.py
```

#### æ‰‹å‹•è½‰æ›
```python
from transformers import AutoTokenizer, AutoModelForCausalLM
import tensorflow as tf

# ä¸‹è¼‰æ¨¡å‹
model_name = "google/gemma-2b"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(model_name)

# è½‰æ›ç‚º TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.int8]

tflite_model = converter.convert()

# ä¿å­˜æ¨¡å‹
with open('gemma_3n_2b_int8.tflite', 'wb') as f:
    f.write(tflite_model)
```

### æ­¥é©Ÿ 4ï¼šéƒ¨ç½²åˆ° Android é …ç›®

1. **è¤‡è£½æ¨¡å‹æ–‡ä»¶**ï¼š
   ```bash
   cp gemma_3n_2b_int8.tflite app/src/main/assets/models/
   ```

2. **è¤‡è£½è©å½™è¡¨**ï¼š
   ```bash
   cp vocab.json app/src/main/assets/
   ```

3. **é©—è­‰æ–‡ä»¶çµæ§‹**ï¼š
   ```
   app/src/main/assets/
   â”œâ”€â”€ models/
   â”‚   â””â”€â”€ gemma_3n_2b_int8.tflite
   â””â”€â”€ vocab.json
   ```

## ğŸ”§ æ›¿ä»£æ–¹æ¡ˆ

### ä½¿ç”¨ä½”ä½ç¬¦æ–‡ä»¶ï¼ˆæ¸¬è©¦ç”¨ï¼‰

å¦‚æœç„¡æ³•ç²å–çœŸå¯¦æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨ä½”ä½ç¬¦æ–‡ä»¶é€²è¡Œé–‹ç™¼å’Œæ¸¬è©¦ï¼š

```bash
# å‰µå»ºä½”ä½ç¬¦æ¨¡å‹æ–‡ä»¶
mkdir -p app/src/main/assets/models
echo "PLACEHOLDER_MODEL_FILE" > app/src/main/assets/models/gemma_3n_2b_int8.tflite

# å‰µå»ºç°¡åŒ–è©å½™è¡¨
cat > app/src/main/assets/vocab.json << 'EOF'
{
  "<pad>": 0,
  "<bos>": 1,
  "<eos>": 2,
  "<unk>": 3,
  " ": 4,
  "hello": 5,
  "world": 6,
  "test": 7
}
EOF
```

### ä½¿ç”¨å…¶ä»–æ¨¡å‹

å¦‚æœ Gemma æ¨¡å‹ä¸å¯ç”¨ï¼Œå¯ä»¥å˜—è©¦å…¶ä»–é–‹æºæ¨¡å‹ï¼š

1. **DistilBERT**ï¼ˆè¼ƒå°ï¼‰ï¼š
   ```python
   model_name = "distilbert-base-uncased"
   ```

2. **GPT-2**ï¼ˆä¸­ç­‰å¤§å°ï¼‰ï¼š
   ```python
   model_name = "gpt2"
   ```

3. **TinyLlama**ï¼ˆå°ˆç‚ºç§»å‹•è¨­å‚™å„ªåŒ–ï¼‰ï¼š
   ```python
   model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
   ```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. æ¨¡å‹ä¸‹è¼‰å¤±æ•—
```
Error: Repository not found or access denied
```
**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- ç¢ºèªå·²ç”³è«‹ Gemma æ¨¡å‹è¨ªå•æ¬Šé™
- æª¢æŸ¥ Hugging Face ä»¤ç‰Œæ˜¯å¦æ­£ç¢ºè¨­ç½®
- å˜—è©¦é‡æ–°ç™»éŒ„ï¼š`huggingface-cli login`

#### 2. å…§å­˜ä¸è¶³
```
OutOfMemoryError during model conversion
```
**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- å¢åŠ ç³»çµ±å…§å­˜æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹
- ä½¿ç”¨æ¨¡å‹åˆ†ç‰‡ï¼š`device_map="auto"`
- å˜—è©¦é‡åŒ–ï¼š`load_in_8bit=True`

#### 3. è½‰æ›å¤±æ•—
```
TensorFlow Lite conversion failed
```
**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- æ›´æ–° TensorFlow ç‰ˆæœ¬ï¼š`pip install --upgrade tensorflow`
- å˜—è©¦ä½¿ç”¨ Optimumï¼š`pip install optimum[tflite]`
- ä½¿ç”¨ä¸åŒçš„é‡åŒ–ç­–ç•¥

#### 4. Android ç·¨è­¯éŒ¯èª¤
```
Asset file not found: models/gemma_3n_2b_int8.tflite
```
**è§£æ±ºæ–¹æ¡ˆ**ï¼š
- ç¢ºèªæ–‡ä»¶è·¯å¾‘æ­£ç¢º
- æª¢æŸ¥æ–‡ä»¶æ¬Šé™
- é‡æ–°åŒæ­¥é …ç›®ï¼š`./gradlew clean build`

### æ€§èƒ½å„ªåŒ–

#### æ¨¡å‹å¤§å°å„ªåŒ–
```python
# æ›´æ¿€é€²çš„é‡åŒ–
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.int8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
```

#### æ¨ç†é€Ÿåº¦å„ªåŒ–
```python
# å•Ÿç”¨ GPU ä»£ç†
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS
]
```

## ğŸ“Š æ¨¡å‹è¦æ ¼

| æ¨¡å‹ | å¤§å° | åƒæ•¸ | é‡åŒ–å¾Œå¤§å° | æ¨è–¦è¨­å‚™ |
|------|------|------|------------|----------|
| Gemma 2B | ~5GB | 2B | ~500MB | 4GB+ RAM |
| Gemma 7B | ~14GB | 7B | ~1.5GB | 8GB+ RAM |
| DistilBERT | ~250MB | 66M | ~80MB | 2GB+ RAM |
| GPT-2 | ~500MB | 124M | ~150MB | 2GB+ RAM |

## ğŸ”— ç›¸é—œè³‡æº

- [Gemma å®˜æ–¹æ–‡æª”](https://ai.google.dev/gemma)
- [TensorFlow Lite æŒ‡å—](https://www.tensorflow.org/lite)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [Android ML Kit](https://developers.google.com/ml-kit)

## ğŸ“ æŠ€è¡“æ”¯æŒ

å¦‚æœé‡åˆ°å•é¡Œï¼Œè«‹ï¼š

1. æª¢æŸ¥æ—¥èªŒè¼¸å‡ºç²å–è©³ç´°éŒ¯èª¤ä¿¡æ¯
2. ç¢ºèªæ‰€æœ‰ä¾è³´éƒ½å·²æ­£ç¢ºå®‰è£
3. å˜—è©¦ä½¿ç”¨ä½”ä½ç¬¦æ–‡ä»¶é€²è¡Œæ¸¬è©¦
4. æŸ¥çœ‹é …ç›®çš„ Issues é é¢

---

**æ³¨æ„**ï¼šæ¨¡å‹æ–‡ä»¶è¼ƒå¤§ï¼Œè«‹ç¢ºä¿æœ‰è¶³å¤ çš„å­˜å„²ç©ºé–“å’Œç©©å®šçš„ç¶²çµ¡é€£æ¥ã€‚é¦–æ¬¡è¨­ç½®å¯èƒ½éœ€è¦è¼ƒé•·æ™‚é–“ã€‚
